# ch4 트랜지스터에서 CPU로, 이보다 더 중요한 것은 없다

## 4.1 이 작은 장난감을 CPU라고 부른다
- **`트랜지스터(transistor)`**
  - 흔히 우리가 반도체라고 부르는 것으로 지난 200년간 인류 역사상 가장 위대한 발명 중 하나
  - 단순히 전류가 흐르게 하거나 흐르지 못하게 하는 스위치 역할
 
- 이 단순한 스위치를 가지고 인간은 `세가지 회로`를 만들어 냄
  - 스위치 두개가 동시에 켜질 때만 전류가 흐르고 등이 켜짐(AND, 논리 곱)
  - 두 스위치 중 하나라도 켜져 있으면 전류가 흐를 수 있으며 등이 켜짐(OR, 논리 합)
  - 스위치를 닫으면 전류가 흘러 등이 켜짐, 반대로 스위치를 열면 전류가 흐르지 않고 등이 꺼짐(NOT, 논리 부정) 
  
  ![CleanShot 2025-03-09 at 21 50 06@2x](https://github.com/user-attachments/assets/a54d1d8e-a2a4-4904-a672-26baa5dfb705)

- 세가지 논리 회로만 있으면 모든 논리 함수를 표현할 수 있음(논리적 완전성)
  - 세가지 조합을 통해 XOR(베타적 논리합) 회로를 만들 수 있으며, 이를 통해 이진수의 덧셈을 가능하게 할 수 있음
    - 해당 기능을 하는 것을 가산기(adder)라고 함 
  
  ![CleanShot 2025-03-09 at 21 53 38@2x](https://github.com/user-attachments/assets/2f6f9dee-11cb-4b2e-a090-87b65dbaa850)

  - 이 외에도 여러 가지 연산 기능을 만들 수 있는데, 이를 전문적으로 담당하는 계산 담당 모듈이 있는데 이를 **`산술 논리 장치(ALU)`** 라고 함

- 또한, 계산뿐 아니라 `부정 논리곱 게이트(NAND)` 두개를 조합하면 데이터를 저장하는 회로도 만들 수 있음
  - 논리 곱과 논리 부정 게이트를 조합한 게이트로 0과 1의 데이터를 저장할 수 있음 

  ![CleanShot 2025-03-09 at 21 56 09@2x](https://github.com/user-attachments/assets/5cebecb3-068c-4ad2-8229-7b1577ceb562)

  ![CleanShot 2025-03-09 at 21 57 17@2x](https://github.com/user-attachments/assets/e32cd838-76f9-49e5-9b94-f1b8b62cc88d)

- 해당 회로를 이어 붙이게 되면 1비트 이상의 데이터를 연속으로 저장할 수 있게되고, 이 조합 회로를 **`레지스터(register)`** 라고 함

  ![CleanShot 2025-03-09 at 21 58 52@2x](https://github.com/user-attachments/assets/5ed130ac-4871-4da3-bc43-e8538bd74efd)

  - 여기서, 주소 지정, 등 여러 기능과 복잡한 회로로 발전하면서 `메모리(memory)`가 탄생함 

- 다만, 해당 방식처럼 하드웨어에서 모든 기능을 구현하는 것은 비효율 적임
  - 하드 웨어는 쉽게 변하지 않는 반면에, 소프트웨어는 비교적 쉽게 변할 수 있기 때문
  - 앨런 튜닝은 컴퓨터를 `범용 연산 장치`로 명명하고, 컴퓨터(계산기) 자체는 계산의 기능만 제공하고 그 위에 소프트웨어 논리를 통해 다양한 기능을 구현하도록 제안함

- 하드웨어는 계산의 기능만 제공하는데 이 때 제공하는 계산의 기능 단위를 `기계 명령`이라고 함
  - 하드웨어에서 제공하는 기계 명령을 통해 프로그래머가 기능을 구현
  - 해당 기계 명령어를 집합 인터페이스를 어셈블리어라고 함

- 앞서 이야기한 여러가지 하드웨어의 모음을 우리는 CPU(중앙 처리 장치)라고 부르기로 했음(혹은 프로세서)
  - CPU(여러가지 회로의 모음)는 클럭 신호 단위로 각 부분의 회로가 함께 동작할 수 있도록 조정하고 동기화를 수행함

## 4.2 CPU는 유휴 상태일 때 무엇을 할까?
- 실제 컴퓨터를 보면, 많은 프로세스들이 아무런 작업도 하지 않고 특정 이벤트가 발생하여 깨우기를 기다리고 있음
- 이때, CPU는 무슨 작업을 할까?

- 기본 적으로 `프로세스는 운영 체제 내에서 스케줄링 되어 관리되어 지고 있음`
  - 운영 체제는 프로세스마다 우선 순위를 할당하고, 우선 순위에 따라 스케줄러가 스케줄링할 수 있도록 대기열에 프로세스를 넣음

    ![CleanShot 2025-03-09 at 22 11 07@2x](https://github.com/user-attachments/assets/efeda571-b727-442a-a254-84bb6eeb4285)

- 해당 기능을 구현하기 쉬운 방법 중 하나는 무한정 많은 프로세스를 대기열에 넣어 순환하도록 하는 것임

  ![CleanShot 2025-03-09 at 22 13 25@2x](https://github.com/user-attachments/assets/7231c113-952f-4737-a525-39f60b85c040)

- 따라서, 커널 설계자는 유휴 작업이라는 프로세스(System Idle Process)를 만들어 냄
  - 시스템에 스케줄링 가능한 프로세스가 없을 때 스케줄러는 이 유휴 프로세스를 꺼내서 실행함

- CPU를 설계한 설계자는 시스템에 유휴 상태가 존재할 가능성을 고려하여 **`halt 명령어`** 를 만듬
  - 이는 CPU 내부에서 일부 모듈을 절전 상태로 전환하여 전력 소비를 줄일 수 있는 명령어
  - halt는 프로세스의 일시 정지(suspend)와 다르게 모든 프로세스가 실행할 명령어가 없어야 함
- 일반적으로 해당 명령어도 실행을 위해 순환 배치됨 (가급적 절전 상태를 유지하게 하기 위함)

  ![CleanShot 2025-03-09 at 22 16 10@2x](https://github.com/user-attachments/assets/79f74d9e-acfe-45c0-83f1-8e80c17c03f6)

- 즉, 컴퓨터 시스템이 유휴 상태일 때 CPU가 하는 일이 바로 이와 같이 halt 명령어를 계속 수행하는 것임
  - 얼만큼 수행했는지에 따라, 깊은 수면(C3), 더 깊은 수면(C4)로 전환될지 커널이 결정함

- 해당 무한 순환에서 탈출하기 위해서는 `인터럽트(interrupt)`를 사용하면됨
- 원래 컴퓨터 운영체제는 일정 시간마다 타이머 인터럽트를 생성하여 CPU는 프로세스를 나눠서 수행할 수 있었음
- 즉, 유휴 프로세스가 타이머 인터럽트로 일시 중지되면 인터럽트 처리 함수는 시스템에 준비 완료된 프로세스가 있는지 확인하고, 없다면 유휴 프로세스를 계속 실행함

## 4.3 CPU는 숫자를 어떻게 인식할까?
- 컴퓨터 시스템이 이진법인 이유는 전류를 흐르거나(1), 흐르지 못하게(0) 하거나를 제어하는 스위치인 트랜지스터로 이루어져 있기 때문임
  - 이진법은 값고 숫자의 위치가 관계가 있는 위치 기수법을 사용함
  - 따라서, k 비트가 주어지면 정수 2^k개를 표현할 수 있음 

- 정수가 아닌 음수를 표현하기 위해서는 2^k개 중 절반을 음수로 사용하면 되고 이를 구분하는 최상위 비트 플래그를 통해 정수 부호를 결정할 수 있음

  ![CleanShot 2025-03-09 at 22 24 10@2x](https://github.com/user-attachments/assets/2c50c1a1-0367-4753-a9ae-06691c3d7cac)
 
- 최상위 비트를 바꾸는 것외에 나머지 비트를 어떻게 표현할 것인지에 대한 세가지 전략이 있음
  - **`부호-크기 표현법`**
    - 최상위 비트(MSB)를 부호 비트로 사용하고, 나머지 비트는 절댓값을 나타냄
    - 0을 두 가지 방식(양수 0, 음수 0)으로 표현할 수 있음 → 연산이 복잡함
  - **`1의 보수`**
    - 음수를 표현할 때 모든 비트를 반전(1→0, 0→1)하여 저장
    - 덧셈 연산에서 1111 1111로 나오는 경우에는 보정을 위해 캐리(1)를 더해야 하는 경우가 발생
    - 0이 두 가지 방식으로 표현됨(0000 0000 = +0, 1111 1111 = -0) 
  - **`2의 보수`**
    - 음수를 표현할 때 1의 보수에서 1을 더한 형태로 저장
    - 0이 단 하나의 표현만 존재함 → 연산이 단순해짐
    - 컴퓨터 친화적으로 가장 널리 사용됨 (덧셈·뺄셈 연산이 자연스럽게 처리됨) 

- 참고로, 사실 CPU는 숫자라는 개념이 없음
  - 모든 것은 인간의 두뇌에 존재하는 개념/약속에 불과함
  - 따라서, 실수가 발생할 수도 있기 때문에 숫자 형식이 가질 수 있는 범위에 대해 알고 있어야 하며, CPU 자체는 인간의 개념에서 나온 내용을 이해하지 못한다는 것을 반드시 인지해야함

    ![CleanShot 2025-03-09 at 22 27 40@2x](https://github.com/user-attachments/assets/ca23e5eb-f59d-4693-9344-7dcb6aaa0426)

  - 즉, 비트를 해석하는 것은 인간(프로그래머)가 만든 소프트웨어임 
 
## 4.4 CPU가 if문을 만났을 때
- 현대 CPU는 if 문과 같은 분기(branch)가 있을 경우, 어떤 방향으로 실행될지 미리 예측하여 수행하는 분기 예측(branch prediction) 기술을 사용함
  - 예측이 맞으면 성능이 최적화되지만, 틀리면 수행한 명령어를 취소하고 다시 실행해야 하므로 성능이 저하됨
  - 분기 예측은 과거 실행 패턴을 기반으로 동작하므로, 규칙적인 분기는 높은 예측 성공률을 가짐
  - 따라서, if문에서 랜덤한 값을 분기 처리하는 경우에 분기 예측율이 떨어지게 되고 성능이 저하되는 현상을 보임
  
   ![CleanShot 2025-03-09 at 22 39 23@2x](https://github.com/user-attachments/assets/86d0c81d-cd99-4131-acc6-26d24f231e1f)

- 분기 예측 기술이 무엇인지 이해하기 위해서는 CPU 파이프라인(pipeline) 기술부터 이해해야함
- CPU 파이프라인은 여러 명령어를 겹쳐서 실행하는 기술
  - 하나의 명령어가 실행되는 동안 다음 명령어를 미리 가져오고, 또 다음 명령어를 디코딩하는 식으로 여러 작업이 동시에 진행됨
  - 보통 하나의 명령어를 처리하는 과정은 명령어 인출(IF), 명령어 해독(ID), 실행(EX), 다시 쓰기(WE) 단계로 이루어짐
    - 각 단계는 별도의 하드웨어에서 처리됨
    - 하나의 명령어 또한 내부적으로 여러 단계로 나누어서 실행할 수도 있음 

  ![CleanShot 2025-03-09 at 22 35 17@2x](https://github.com/user-attachments/assets/8baa0716-91cd-47a7-bc67-09cd8878d3ea)

- 그런데 if를 만나게 되면, 조건부 점프 명령어로 변환되어 해당 명령어는 다른 명령어를 호출함. 이는 파이프라인 기술과 만나면서 문제가 될 수 있음
  - 왜냐하면, 분기에 따라 다른 명령어를 실행하기 전에 미리 준비해두어야 하는데 무엇을 준비해야할지 모르기 때문에 분기를 예측하는 행위를 수행함

    ![CleanShot 2025-03-09 at 22 43 46@2x](https://github.com/user-attachments/assets/e9bcb49a-04a0-482d-b447-9900c4df5431)
  
    ![CleanShot 2025-03-09 at 22 44 54@2x](https://github.com/user-attachments/assets/9c9a03e3-0147-4757-8c78-050465957b35)

- 이러한 예측은 프로그램 실행 이력을 기반으로 여러가지 데이터를 기반으로 판단함
  - 따라서, 랜덤한 값은 분기 예측률을 저하시킴
  - 높은 성능을 요구하는 코드를 작성하고자 한다면 CPU가 높은 확률로 추측할 수 있도록 코드를 작성해야함
  - 현대에서는 컴파일러가 이러한 최적화를 수행해주는 역할까지 해줌(또한 최신 CPU의 분기 예측은 매우 높은 편임)

## 4.5 CPU 코어 수와 스레드 수 사이의 관계는 무엇일까?
- CPU가 사용자 상태에서 실행하는 명령어는 모두 아래 처럼 스레드에 속해 있음 

  ![CleanShot 2025-03-16 at 22 08 42@2x](https://github.com/user-attachments/assets/58d96e9b-e01d-4c76-b450-10b392c0a7a2)

- 사실 CPU와 스레드는 어떤 필연적인 관계는 없음
  - 따라서, 단일 코어에서도 다중 스레드 프로세스를 실행시킬수 있음
  - 스레드는 소프트웨어 측면에서의 실행 흐름이자 작업의 단위일뿐, CPU는 어떤 스레드인지는 본인이 무엇을 실행하고 있는지 전혀 모르고 관심도 없음
  - 이걸 알고 이해하는 것(실행하고 있는 명령어가 무엇인지)은 운영체제가 하는 일임

- `CPU는 단지 PC 레지스터 주소에 따라 메모리에서 기계 명령어를 꺼내 실행할 뿐`

  ![CleanShot 2025-03-16 at 22 12 44@2x](https://github.com/user-attachments/assets/83bbed0a-43c8-4d0f-ab42-29ae872ceb9a)

- 사실 스레드라는 개념은 프로그래머에게 매우 편리한 추상화 방법을 제공하는 것임
  - 각각의 하위 작업을 별도의 스레드에 배치하면 운영체제에서 이를 스케줄링하고 실행하기 때문에, 동시에 여러 작업을 실행할 수 있음 
  
    ![CleanShot 2025-03-16 at 22 14 15@2x](https://github.com/user-attachments/assets/1a1b2754-8593-42f7-85a5-526476c71f43)

  - 주의해야하는 것은 처리해야 하는 작업이 블로킹 입출력과 관련이 있을때 해당 블로킹 호출이 실행되면 운영 체제가 전체 스레드를 일시 중지하므로 해당 호출 뒤에 있는 코드는 실행되지 않음 

- 일반적으로 `생성되는 스레드 수는 코어 수와 일정한 선형관계를 유지해야함`
  - 스레드가 **무작정 많다고 좋은 것은 아님**
  - 입출력이나 동기화 같은 작업이 없다면, 코어당 스레드 하나가 가장 나은 선택

- 왜냐하면, 스레드 수가 많으면 스레드 컨텍스트 스위칭이 자주 발생하게 되는데(동시에 여러개 작업을 해야하기 때문에) 이는 부담의 증가로 이어짐
- 적절한 스레드 수는 상황마다 다르기 때문에 지속적으로 테스트하면서 조정해야함
  - 적정 스레드 개수 = CPU 코어의 수 * ( 1 + 대기시간 / 작업시간 ) 

## 4.6 CPU 진화론(상)
- CPU는 본질적으로 프로그램에 따른 차이가 없음
  - 복잡한 대규모 소프트웨어이든 간단한 계산기이든 동일하게 컴파일러로 컴파일된 기계 명령어 실행 파일일 뿐

- 즉, CPU 입장에서는 기계 명령어를 실행하기만 하면됨
- CPU는 명령어 집합을 통해 프로그래머에게 어떤 기능이 사용 가능한지 제공함
- 문제는 서로 다른 CPU는 다른 유형의 명령어 집합을 가지고 있었음
- 이는 프로그래머가 코드를 작성하는 것을 매우 어렵게 하고, 명령어 집합에 따라 하드웨어 설계가 달라지는 문제도 있었음

- 이 명령어 집합을 어떤 식으로 제공하는지, 어떤 설계, 구조를 가지는지에 따라 크게 두개로 나뉘어짐
  - `복잡 명령어 집합 컴퓨터(CISC)` : x86(Intel, AMD)
  - `축소 명령어 집합 컴퓨터(RISC)` : ARM(M1)

- 초기엔 복잡 명령어 집합이 인기였음
  - 왜냐하면, 1970년대 까지만 해도 어셈블리어로 코딩을 하는 경우가 많았음
  - 따라서, 보다 많은 기능을 하드웨어 측에서 제공해주는 것이 개발자에겐 편리하였음

- 그당시 많은 프로그래머들은 의미상 간격을 이어주기를 원했음
- 즉, 함수 호출, 순환 제어, 주소 지정 패턴, 등의 개념과 대응되는 기계 명령어가 있기를 바람
  - 하드웨어 측에서 API를 제공해주면 개발하는 사람 입장에서는 가져다가 쓰기만 하면 되니 편리함

- 이외에도 저장 공간을 절약하기 용이했음
  - 기계 명령어의 길이가 가변적으로 프로그램 자체가 차지하는 저장 공간을 줄일 수 있었음
  - 기계 명령어는 밀도를 높여 인코딩 되어 공간을 절약함

- 단점
  - CPU 설계와 디버깅 복잡도가 높아짐
  - 명령어 길이가 고정되어 있지 않아 복잡한 연산, 등이 포함되면 문제가 더 악화됨
  - 하드웨어에서 제공하는 기능이다 보니 소프트웨어에 비해 유연성이 떨어짐  

- 이러한 단점을 보완하기 위해 마이크로 코드 가 등장함
  - 대부분의 명령어에 포함된 연산을 더 간단한 명령어로 구성된 작은 프로그램으로 정의하고 이를 CPU에 저장하면, 모든 기계 명령어에 대응하여 전용 하드웨어 회로를 설계할 필요가 없어짐
  
  ![CleanShot 2025-03-16 at 22 28 50@2x](https://github.com/user-attachments/assets/cfa4a90a-f25a-4c21-a085-22c8912366d1)

## 4.7 CPU 진화론(중)
- 세상이 변화하면서 기존에 문제였던 컴파일러의 성능이 매우 우수해졌고, 저장 장치의 용량이 기하급수적으로 늘어나기 시작함
- 이런 시대의 흐름에 맞춰, 데이비드 패턴슨은 마이크로 코드를 개선하여, 축소 명령어 집합이라는 개념을 만들어냄
  - 복잡 명령어 집합에서 성능을 향상 시키는 것으로 여겨지는 마이크로 코드가 오히려 CPU 내부에서 작동이 되기 때문에 병목이 되어 버림
    - 여러 API의 조합을 최적화해서 비동기로 호출하더라도 API 자체가 비효율적이라면 개선할 수 없는 상황 

- 축소 명령어 집합의 탄생
  - 간단한 명령어 여러개로 복잡한 명령어를 대체함
    - CPU 제어 능력 향상
    - 하나의 명령어당 들여야하는 연산이 더 간단함

  - 컴파일러를 최대한 활용 가능
    - 시대적으로 어셈블리어를 사용하기 보다 컴파일러를 활용하여 프로그램을 작성하는 사람이 많아짐

  - LOAD/STORE 구조
    - 축소 명령어 집합에서는 레지스터 내 데이터만 처리할 수 있으며, 메모리 내데이터는 직접 처리하지 못함
    - 이를 통해 명령어 파이프라인을 활용할 수 있음 

- 1세대 축소 명령어 집합 프로세서는 전체가 파이프라인 기반으로 설계 되어 명령어 하나가 1~2클럭 주기로 실행됨
  - 반면에, 복합 명령어 집합에서는 명령어 하나를 실행하는데 5~10클럭 주기가 필요함 

- 축소 명령어 집합 구조에서는 더 유연하고 최적화되고 작은 CPU를 설계할 수 있음
- 이로 인해, 이시기에는 축소 명령어 집합 컴퓨터가 복잡 명령어 집합보다 인기를 끌게됨 

## 4.8 CPU 진화론(하)
- 그들을 이길 수 없다면 그들과 함께하라
- 복잡 명령어 집합 진영에서도 시대의 흐름에 맞춰서 복잡 명령어 인터페이스는 그대로 두고, 하위에 구현에서 마이크로 명령어 개념을 제시하여 상황을 반전함

  ![CleanShot 2025-03-16 at 22 42 24@2x](https://github.com/user-attachments/assets/36a4fc42-0da8-4a32-b5db-67a50b858596)

- 마이크로 명령어는 개념은 사실 상 축소 명령어와 동일하다고 보면됨
  - 따라서, 축소 명령어가 가진 장점을 활용할 수 있게됨(파이프라인 기술, 등) 

  ![CleanShot 2025-03-16 at 22 43 05@2x](https://github.com/user-attachments/assets/39935874-8a5d-4e67-b241-9697ae7f77be)

- 또한, 하이퍼 스레딩이라는 기술을 통해 우위를 가져감
  - CPU 코어 한개가 CPU 코어 여러 개인것 처럼 보이게 하는 기술
  - 파이프라인 기술에서 명령어 간 종속성으로 파이프라인이 항상 완벽하게 채워진 상태에서 실행될 수 없었는데 이 빈공간을 추가 명령어 흐름을 도입하면서 CPU의 리소스를 최대한 활용함 

  ![CleanShot 2025-03-16 at 22 44 58@2x](https://github.com/user-attachments/assets/cab110a0-15da-4913-bb4f-294b67ebb236)

- 다만, 최근에 모바일이 대세가 되고, 애플의 M시리즈 칩이 등장하면서 저전력의 효율을 극대화하는 방향으로 축소 명령어 집합 진영이 다시 붐을 맞이하고 있음

- 결론적으로 각 진영은 각자의 장점을 가져가고 단점을 보완하는 방식으로 계속 발전 중임
  - 경계가 많이 허물어지고는 있으나 아직 차이는 있음 

- 이러한 기술 발전의 역사를 보면 기술의 발전은 시대의 상황에 따라 필연적임
  - 시대 상황에 맞게 문제를 해결하는 방식으로 발전함 

## 4.9 CPU, 스택과 함수 호출, 시스템 호출, 스레드 전환, 인터럽트 처리 통달하기
- CPU 에 레지스터가 필요한 이유는 CPU와 메모리 간의 속도 차이 간극을 메우기 위함임
- CPU 에는 임시 데이터 보관하는 레지스터 외에도 여러 가지 유형의 레지스터가 있음
  - 스택 포인터
  - 명령어 주소 레지스터
  - 상태 레지스터

 - 레지스터에 저장되어 있는 모든 정보를 일반적으로 `상황 정보(Context)`라고 함
   - 프로그램 동작에 필요한 문맥, 현재 상황
   - 해당 상황, 문맥 정보만 있다면 실행을 일시중지, 재개가 얼마든지 가능해짐
  
 - CPU에 이러한 상황 정보가 필요한 이유는 CPU가 엄격한 오름차순, 순서대로 기계 명령어를 수행하는 것이 아니기 때문에
   - 함수 A에서 B로 점프
   - 커널 코드를 실행하기 위해 커널 모드로 전환
   - 여러 프로그램의 명령어를 나눠서(동시에) 실행
   - 인터럽트 처리를 위해 실행 중인 프로그램을 중단

   ![CleanShot 2025-03-14 at 00 34 53@2x](https://github.com/user-attachments/assets/c75d70b3-3be9-4cae-bf34-e386bbbf678e)

- 이러한 기능들을 구현하기 위해서는 상황 정보의 저장과 복원이 가능해야함
  - 스택 구조로 데이터를 저장하고 있음 

  ![CleanShot 2025-03-16 at 22 50 52@2x](https://github.com/user-attachments/assets/f4eafecf-3c48-4df6-a8e5-68350d03dc48)

