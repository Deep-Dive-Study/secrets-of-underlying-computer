# 5장 작은 것으로 큰 성과 이루기, 캐시

폰 노이만 구조에서는 기계 명령어와 명령어에서 사용하는 데이터가 메모리에 저장되어야 하며, CPU가 기계 명령어를 실행할 때 먼저 명령어를 메모리에서 읽어야 한다.

또 명령어를 실행하는 과정에서 데이터를 메모리에서 읽어야 할 수도 있고, 계산 결과 저장은 메모리에 저장해야 한다.

즉 폰 노이만 구조는, CPU가 실행하는 기계 명령어와 처리하는 데이터가 모두 메모리에 저장되어 있어야 한다.

## 5.1 캐시, 어디에나 존재하는것

폰 노이만 구조는, CPU가 실행하는 기계 명령어와 처리하는 데이터가 모두 메모리에 저장되어 있어야 함.

* CPU는 최대한 레지스터에 있는 데이터만 가지고 연산하려고하는데, 레지스터에 해당 데이터들이 없으면 메모리에 접근하게됌. 그러나, 레지스터랑 메모리는 속도차이가 엄청나기 때문에 속도가 느릴 수 밖에 없음. 
  * 레지스터 1ns 이하, L1캐시 : 1~4ns, L2캐시 3~10ns, L3캐시 10~30ns 그러나 RAN은 50~100ns = 50~500배 차이 

메모리 벽(wall) 또는 폰 노이만 병목 현상이라고 함. 

### CPU와 메모리의 속도 차이 

보통 CPU 속도는 클록 속도 를 이야기 함. 3.5GHZ는 1초에 35억번 연산 수행

* 그러나 클럭 사이클당 처리할 수 있는 명령어 수 코어 수, 등 다른 요소들도 있어서 위는 그냥 일반적인 숫자 이야기

- CPU 내부에서 연산할 때는 **레지스터에 있는 데이터**를 사용하면 빠름 (**1ns 이하**).
- 하지만 메모리(RAM)에서 데이터를 불러오려면 **최소 100ns 이상 걸림**.
- CPU가 3.5GHz라면 **1클록(사이클)** 에 약 0.3ns 정도 걸리는데, RAM 접근이 100ns라면 **CPU는 300클록 이상을 그냥 기다려야 함**.

즉, **CPU 속도가 빨라도 RAM이 느리면 CPU가 메모리 접근 대기 시간 때문에 실제 성능이 떨어질 수 있음**.

CPU랑 주 상주 메모리 속도 차이가 너무 심하니, 매우 저용량의 L1, L2, L3 캐시를 둬 병목 현상을 완화 하고자 했음.

* 캐시 안의 캐시?같은개념 

* L1캐시 접근 속도 : 대략 4클럭 = 1ns, L2 : 10클럭 : 3ns, L3 : 50클럭 : 15ns 
  * 1(1초) / 35억 = 0.2857ns = 0.29ns  

CPU가 메모리 사용시 순서대로 레지스터 -> L1 -> L2 -> L3 -> 메모리 순으로 뒤지고 나서 

찾으면 다시 캐시에 저장하여 캐시에 데이터를 갱신함 

* 일반적으로 **L1 → L2 → L3 순으로 갱신됨** (CPU의 캐시 정책에 따라 다를 수 있음).
* **CPU는 먼저 L1 캐시에 데이터를 저장하고, L2/L3에도 복사할 수 있음**.

### 공짜 점심은 없다 : 캐시 갱신

CPU는 캐시에 기록하여 일을 처리하는데, 갱신시 문제가 캐시 데이터는 갱신되었지만 메모리 데이터는 아직 과거 데이터로 불일치 문제가 발생할 수 있다.

캐시를 사용하는 모든 컴퓨터가 가진 문제이다.

이 문제를 해결하는 가장 쉬운 방법은 캐시 갱신시 메모리도 함께 갱신하는 wirte-through 방법이다

그러나 이 방법도 단점이 있다. 일관성은 보장되지만 캐시 갱신 이후 메모리를 갱신해야 하는데 이때 레이턴시 때문에 느리고 멈춰있게 된다. -> 동기식 방식

이를 최적화 하는 방법은 캐시 갱신과 메모리 갱신을 비동기로 처리하는것.

메모리에 기록할 때는 캐시를 직접 갱신하지만, 갱신이 완료를 기다리지 않고 다음 명령어를 수행하고 비동기로 갱신하면 된다. (Write-back 방식)

즉

* Write-Through 방식 : CPU가 데이터를 캐시에 쓰면 즉시 RAM에도 반영. 데이터 일관성이 보장되지만 속도가 느림. 
* Write-Back 방식 (일반적으로 많이 사용됨) CPU가 데이터를 캐시에만 저장하고, RAM에는 나중에 반영. 성능이 뛰어나지만, 전원이 꺼지면 데이터 손실 위험이 있음. 
  * 즉, **CPU는 데이터를 캐시에만 저장하고 RAM 갱신은 캐시 컨트롤러라는 다른 하드웨어가 비동기적으로 수행**

### 다중 코어 캐시의 일관성

CPU가 메모리 접근 성능을 올리기 위해 캐시를 추가했지만, 코어 여러개를 사용하는 모던 시스템 상 다른 문제가 발생할 수 있음. 여러 코어가 같은 X변수를 바라볼때 중복 업데이트나 더티 연산이 발생할 수 있는것. -> 동시성 문제 

이 문제의 해결방법은, 캐시 한 개에서 갱신된 변수가 다른 CPU 코어의 캐시에도 존재하면 해당 캐시도 함께 갱신하는것. 변수 업데이트시, 자체 캐시랑 메모리만 신경쓰는것이 아니라 해당 변수가 다른 코어의 캐시에도 있는지 확인하고 있다면 갱신해야 함.

* 딱 봐도, 성능을 떨어트리는 연산임.

해결하는 대표적인 방법이 **MESI 프로토콜 (Modified, Exclusive, Shared, Invalid)**

* Modified (M, 수정됨)	이 캐시에서만 데이터를 가지고 있으며, RAM과 다름. 다른 캐시는 이 데이터를 갖지 않음.
* Exclusive (E, 독점적)	이 캐시에서만 데이터를 가지고 있으며, RAM과 같음. 다른 캐시는 이 데이터를 갖지 않음.
* Shared (S, 공유됨)	여러 캐시에서 같은 데이터를 가지고 있으며, RAM과 같음.
* Invalid (I, 무효화됨)	다른 코어가 데이터를 수정했으므로, 이 캐시의 데이터는 더 이상 유효하지 않음.

* 각 캐시에 상태를 두고  **CPU가 데이터를 변경하면, 다른 코어의 캐시 데이터를 무효화함 (Invalid 상태로 변경)** 해서 서로 알아서 동기화 하게 함

### 5.1.5 메모리를 디스크의 캐시로 활용하기

| 저장장치                 | **지연 시간 (Latency)**             | **대역폭 (Bandwidth, 속도)** | **특징**                               |
| ------------------------ | ----------------------------------- | ---------------------------- | -------------------------------------- |
| **CPU 레지스터**         | **1ns 이하**                        | **수백 GB/s**                | 가장 빠른 저장 공간                    |
| **L1 캐시**              | 1~4ns                               | 수백 GB/s                    | CPU 코어 내부                          |
| **L2 캐시**              | 3~10ns                              | 수십~수백 GB/s               | CPU 코어 근처                          |
| **L3 캐시**              | 10~30ns                             | 수십 GB/s                    | 여러 코어 공유                         |
| **RAM (DDR4, DDR5)**     | **50~100ns**                        | **25~100GB/s**               | 캐시보다 느리지만 SSD보다 수천 배 빠름 |
| **SSD (NVMe, PCIe 4.0)** | **100,000ns (100μs)**               | **2~7GB/s**                  | RAM보다 1,000배 느림                   |
| **SSD (SATA3)**          | **0.1~~0.5ms (100,000~~500,000ns)** | **500MB/s**                  | NVMe SSD보다 4~10배 느림               |
| **HDD (하드디스크)**     | **10ms (10,000,000ns)**             | **100~200MB/s**              | SSD보다 50~100배 느림                  |

디스크는 탐색(seek)를 위해 10ms 가량이 소요됌. 

* 메모리 vs 디스크 속도 차이 : 10ms=10×1,000,000ns=10,000,000ns =100,000 배
  * 1 밀리세컨드(ms) = **1,000 마이크로세컨드(μs)** = **1,000,000 나노세컨드(ns)**

파일을 읽을라면 데이터를 디스크에서 메모리오 옮겨야 CPU가 파일의 데이터를 읽을 수 있음. 

너무 느리기 때문에 OS는 일부 공간이 남아있는 메모리를 디스크 캐시로 활용하여 디스크에서 데이터 읽어 오는 일을 최소화 함. 이것이 리눅스의 페이지 캐시의 기본 원리

캐시가 추가되면 반드시 캐시 갱신 문제가 발생하므로, 대부분 입출력 라이브러리가 동기화 또는 flush(캐시비우기) 함수 제공함.

### 가상 메모리와 디스크

프로세스는 자체적인 표준 크기의 주소 공간을 가져, 물리 메모리와는 관련 없이 물리 메모리 크기를 초과하는 주소 공간을 가지고 있음. 

시스템에 N개 프로세스가 있을 때, N개가 실제 물리 메모리를 모두 사용한다면, 새로운 프로세스는 N + 1 메모리를 요청하면 이걸 어떻게 처리할 수 있을까?

일부 프로세스에서 사용하던, 자주 사용하지 않은 메모리 데이터를 디스크에 기록하고 이 데이터가 차지하던 물리 메모리를 해제하고 N + 1 프로세스한테 할당한다.

* 즉 디스크를 메모리의 창고 역할을 하게 함

### CPU는 메모리를 어떻게 읽을까

CPU가 볼 수 있는것은 모두 가상 메모리 주소. 즉 모든 연산에 사용하고 나오는 결과도 다 가상 메모리 주소임.

실제 물리 메모리 주소로 변환 해야 어디에 저장, 읽을지 알 수 있음.

* 가상 메모리 → 물리 메모리 변환 과정은 MMU(Memory Management Unit)와 운영체제가 담당

변환이 완료되면 캐시 -> 메모리 -> 디스크 순으로 접근함.

### 5.1.8 분산 저장 지원

한대의 컴퓨터로 대용량 데이터를 모두 저장할 수 없음. 그래서 분산 파일 시스템을 이용함

로컬 디스크는 원격 분산 파일 시스템에서 전송된 파일을 저장함. 

<img src="./images//image-20250309000828706.png" width = 350>

이를 사용할 때는 네트워크를 통하지 않고 로컬에 접근하여 원격의 분산 파일 시스템의 캐시로 간주 가능. 

물론 응답 속도를 높이려고 카프카처럼 원격에 있는 데이터를 메모리로 끌어올 수도 있음. 

자 이제 캐시에 대해 알았고, 각 계층에 대한 저장 용량은 반드시 다음 계층 보다 작아야 함.

이유

1. L3가 메모리보다 크면 걍 L3를 메모리로 쓰면됌
2. 메모리보다 L3, L2, L1 캐시가 상대적으로 매우 비쌈
3. 성능 문제 : 캐시가 커지면 속도도 느려짐. 
4. 지역성의 원칙 : 캐시가 효과적으로 작동하려면 Locality 원칙을 따라야 함. 계층이 작을수록 빠르게 필요한 데이터를 찾을 확률이 높아짐
   - **공간 지역성(Spatial Locality)**: 가까운 데이터가 자주 사용됨.
   - **시간 지역성(Temporal Locality)**: 최근 사용한 데이터가 다시 사용됨.
5. CPU 내부에 그렇게 큰 캐시를 넣을 공간이 없음.

## 5.2 어떻게 캐시 친화적인 프로그램을 작성할까?

캐시 적중률이 높아져야 결국 캐시를 사용하는 의미가 있다. 없어서 다른데 뒤지면 그것은 그 나름대로 손해. 바로 그냥 다른데 뒤지고말지.

이는 지역성의 원칙을 생각하면서 설게하는것이 좋다. 

### 5.2.1 지역성의 원칙

locality of reference 의 본질은 프로그램이 매우 규칙적으로 메모리에 접근함.

프로그램이 메모리 특정 부분에 접근하고 나서 해당 부분을 여러 번 참조하는 경우를 temporal locality 라고 함.

또한 프로그램이 특정 부분 참조시, 인접한 메모리도 참조할 수 있는데 이를 spatial locality라고 함. 

* 배열, 구조체(struct), 연속적인 메모리 블록에서 자주 발생

### 5.2.2 캐시 친화 프로그래밍 원칙 몇가지

c / c ++에서 malloc, new 사용하면 힙 영역의 이곳 저곳에 흩어질 가능성이 높아 공간 지역성이 별로 안좋음

메모리 풀 기술을 이용하여 커다란 메모리를 할당받고 이 안에서 다 쓰고 모자르면 또 하는것이 좋음.

* 메모리 풀 기술은 그냥 큰 객체를 구조체로 만들어 놓고, 여기서 할당받아 쓰는것을 의미하는 듯?

### 5.2.6 다차열 배열 순회

**잘 못된 코드 (지역성 활용 X)**

```c
int arr[1000][1000];

// 열 우선 방식 (캐시 비효율적)
for (int j = 0; j < 1000; j++) {
    for (int i = 0; i < 1000; i++) {
        arr[i][j] += 1;
    }
}
```

- **공간 지역성을 활용하지 못함** (캐시 미스 증가)
- **메모리 접근 성능 저하**

왜? 메모리는 행 우선으로 데이터를 저장하므로 특정 행 읽으면 해당 배열의 가로부분을 같이 읽어와 캐시처럼 사용 가능 . 반면 당연히 세로(열)로 접근하면 , 행을 건너 뛰어서  한번에 읽어오지 못하기 때문에 캐시 적중을 할 수가 없음. 



캐시 사용시, 성능 분석 도구를 이용해서 캐시 적중률이 시스템 성능의 병목이 되는지 판단해야 한다 .

| 도구                | 플랫폼            | 기능                               |
| ------------------- | ----------------- | ---------------------------------- |
| **Redis MONITOR**   | Redis             | 캐시 적중률 분석 및 키 조회율 추적 |
| **Memcached Stats** | Memcached         | 캐시 미스율 및 요청 분석           |
| **JVM VisualVM**    | Java (Heap Cache) | JVM 메모리 캐시 분석               |
| **Python cProfile** | Python            | 함수별 캐시 사용률 분석            |

캐시가 다중 스레드를 만나면 새 문제가 생긴다

## 5.3 다중 스레드 성능 방해자

### 5.3.1 캐시와 메모리 상호 작용의 기본 단위: 캐시 라인

공간 지역성 원리로, 접근해야 할 데이터만 캐시에 저장하는것보다 해당 데이터가 있는 곳의 묶음 데이터를 캐시하는것이 더 좋다.

이 묶음 데이터는 cache line 이라는 이름을 가지고 있따.

이 묶음 크기는 일반적으로 64바이트이다.

### 5.3.2 첫번째 성능 방해자 : 캐시 튕김 문제

1번 프로글매

```c++
#include <iostream>
#include <thread>
#include <atomic>

std::atomic<int> a;

void threadf() {
    for (int i = 0; i < 500000000; i++) {
        ++a;
    }
}

void run() {
    std::thread t1(threadf);
    std::thread t2(threadf);
    
    t1.join();
    t2.join();
}

```

2번 프로그램

```c++
#include <iostream>
#include <atomic>

std::atomic<int> a;

void run() {
    for (int i = 0; i < 1000000000; i++) {
        ++a;
    }
}
```

2번 프로그램이 1번 프로그램보다 일반적으로 빠름.

리눅스 perf로 분석해보면, 한 클럭 주기당 기계 명령어 실행 횟수가 1번이 훨씬 적음 => 느리다

왜 그럴까?

* 이전에 이야기한 MESI 프로토콜 때문임. (동기화)

캐시 일관성 보장 위해, 두 코어의 캐시에 전역변수 a가 모두 저장됌. 

첫번째 스레드가(코어) a 변수 연산 실행시, 두번째 코어(스레드의) 캐시의 a변수를 무효화(invalid) 처리 해야 한다.

* 여기서 첫번째 캐시 튕김 발생

이후 두번쨰 코어(c2) 연산시 캐시 무효화여서 어절 수 없이 메모리에서 a 변수 값을 읽어야 함. 마찬가지로 연산을 해야하므로 첫번째 코어(c1)의 변수를 무효화 해야 하고, 또 캐시 튕김 발생 

이렇게 끈임없이 서로 상대 캐시를 무효화 하면서 튕겨 내어서 이를 캐시 튕김 또는 핑퐁 이라고 함

때문에 여러 스레드 사이에 데이터 공유를 피할 수 있다면 가능한 판 피하자

* 물론 예제에서는 다른 이유도 있을 수 있다. atomic 변수이기 때문에
  * CAS 연산등을 통한 연산이면, 스핀락처럼 무한정 재시도하면서 맞추기 때문임. 

### 5.3.3 두번째 성능 방해자 거짓 공유 문제

예제 코드 생략. 

```c++
struct data {
  int a;
  int b;
}
```



* 구조체에 a,b 변수를 두고 첫번째 프로그램은 멀티스레드로 각각 a,b 연산, 두번째는 한 함수 내에서 순차적으로 a,b 연산

공유하지 않는 변수 a,b를 각각 업데이트 함. 

마찬가지로 첫번째 프로그램이 더 느림. 

캐시는 64바이트씩 지역성의 원리 중 공간성의 원리 때문에 한 캐시라인씩 올리기 때문에, 하나의 캐시 라인을 공유하고 있을 수 있기 때문. (아닐 수도 있음. 다만 높은 확률임. int4바이트 둘이 붙어있으니 )

개선 방법은 구조체를 분리하거나, a , b 변수 사이에 큰 데이터 int arr[16] (64바이트) 이렇게 두면 한 캐시 라인을 공유하지 않게 되므로 해결 가능. 

## 5.4 봉화희제후와 메모리 장벽

이 이야기와 코드가 강조하는 것은, **스레드 간 동기화 없이 공유 변수를 사용할 경우 예상치 못한 버그가 발생할 수 있다**는 점

### 5.4.8 잠금 프로그래밍과 잠금 없는프로그래밍

꽤 중요한 내용.

### **잠금 프로그래밍 vs. 잠금 없는 프로그래밍 요약**

| 구분          | 잠금 프로그래밍 (Lock-based)                                 | 잠금 없는 프로그래밍 (Lock-free)                             |
| ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **개념**      | 공유 자원 보호를 위해 상호 배제(Mutex) 사용                  | 공유 자원을 사용할 때도 대기하지 않음                        |
| **방식**      | 한 스레드가 리소스를 사용하면 다른 스레드는 대기             | 리소스 사용 중이면 다른 작업을 수행 후 재시도                |
| **종류**      | 1) **Mutex (운영 체제 대기 상태)**  2) **Spinlock (반복 검사, 바쁜 대기)** | 1) **CAS(Compare-and-Swap)**  2) **Lock-free data structures** |
| **장점**      | 구현이 쉽고 직관적                                           | 대기 상태 없이 성능 향상 가능                                |
| **단점**      | 성능 저하(대기 발생), 데드락 위험                            | 코드가 복잡하고 ABA 문제 등 해결 필요                        |
| **사용 예시** | 일반적인 멀티스레드 환경                                     | 실시간 시스템, 높은 성능이 필요한 경우                       |

------

### **설명**

#### **1. 잠금 프로그래밍 (Lock-based Programming)**

- 다중 스레드 환경에서 공유 리소스를 보호하기 위해 **상호 배제(Mutex)** 를 사용한다.
- 한 스레드가 리소스를 사용 중이면, 다른 스레드는 반드시 대기해야 한다.
- 종류:
  - **Mutex**: 운영 체제가 다른 스레드를 대기 상태로 변경 (비효율적일 수 있음)
  - **Spinlock**: 다른 스레드가 계속해서 잠금이 풀렸는지 확인 (CPU 사용량 증가)
- ReentrantLock, Mutex, Semaphore

#### **2. 잠금 없는 프로그래밍 (Lock-free Programming)**

- 공유 리소스를 사용 중이어도 다른 스레드는 대기하지 않고 다른 작업을 수행한다.
- 스레드가 대기하지 않기 때문에 **실시간 시스템**에서 중요하게 사용된다.
- **CAS(Compare-and-Swap)** 같은 원자적 연산을 사용하여 공유 리소스를 안전하게 업데이트한다.
- 구현이 어렵고 **ABA 문제** 같은 추가적인 해결책이 필요하다.
  - A 변수에 대해 연산을 하는 경우, A 변수가 안바뀌었으면 성공, 바뀌었으면 실패 및 재시도 처리를 해서 성공할때까지 재시도 하는것. 단 A 변수가 5 -> 6 -> 5 ( A -> B -> A)로 바뀐 것에 대해선 감지할 수 없음.
    - 일반적으로 **락을 획득하려는 것이 아니라, 데이터를 원자적으로 업데이트하는 목적**.
    - 이경우 뭐 버전 태그? 등을 사용해서 비교하기도 함. 
- Atomic 클래스들. 

즉 일반적인 상황에서는 **잠금 프로그래밍**을 사용하지만, 성능이 중요한 경우에는 **잠금 없는 프로그래밍**을 고려해야 한다.

잠금 없는 방식이 성능이 좋을 수 있지만, 코드가 복잡하고 디버깅이 어려울 수 있다.

**목표는 최소한의 잠금으로 효율적인 동기화를 구현하는 것**이다.

